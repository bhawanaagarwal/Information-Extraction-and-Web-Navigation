{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e38193",
   "metadata": {},
   "source": [
    "                                                                                                             Bhawana Agarwal\n",
    "# Automating Information Extraction and Web Navigation             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931252c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project focuses on simplifying the tasks of extracting information from images and efficiently navigating the web. We're using two tools: PyTesseract for converting images to text and a web crawler with the Google Search API. The main objective is to automate the process of getting a list of company names from an image and then finding career page links online.\n",
    "\n",
    "Starting with PyTesseract, it's a Python tool that helps us convert the visual data of company names from an image into readable text. This eliminates the need for manual data entry and ensures accuracy.\n",
    "\n",
    "Moving on to the web crawler, we use the Google Search API to search for career page links related to the identified companies. This integration makes our web searches more targeted and efficient, saving time and effort.\n",
    "\n",
    "So, let's get started!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f17a22",
   "metadata": {},
   "source": [
    "To initiate the project, I set up a new conda environment dedicated to this task. This ensures a clean and isolated space for our project. Then we install the required libraries for this project, for example Pillow to read the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15b37f",
   "metadata": {},
   "source": [
    "Unlike some other libraries that can be installed with a simple 'pip install' statement, using PyTesseract requires an additional step due to its dependence on the Tesseract OCR engine. (OCR - Optical Character Recognition)\n",
    "\n",
    "Specifically:\n",
    "\n",
    "- **For Windows users**, it's necessary to download the Tesseract executable file. The path to this executable needs to be specified in the PyTesseract configuration. This ensures that PyTesseract can utilize the Tesseract OCR engine correctly. __[Here is the link to download tesseract for windows](https://github.com/UB-Mannheim/tesseract/wiki)__ </br></br>\n",
    "\n",
    "- **For macOS users**, installation guidelines for Tesseract on a Mac are available. Following these guidelines ensures that PyTesseract functions seamlessly. __[Here is the link to install tesseract for mac](https://tesseract-ocr.github.io/tessdoc/Installation.html)__\n",
    "\n",
    "If you want more information on tesseract, use the following resources:\n",
    "- https://github.com/tesseract-ocr/tesseract\n",
    "- https://pypi.org/project/pytesseract/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d7707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48cef80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce1380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pytesseract import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742f8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tesseract = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "pytesseract.tesseract_cmd = path_to_tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa7a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I have used single image as per my use-case, but one can tweak this program to read multiple images in a list with loop.\n",
    "# I have tested it and it works\n",
    "\n",
    "image_path = r\"C:\\Users\\PC\\Downloads\\sample_tier_list.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7222c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_convert_img_to_txt(img_path):\n",
    "    \"\"\"\n",
    "    Reads text from an image file using Tesseract OCR.\n",
    "\n",
    "    Parameters:\n",
    "        - img_path (str): The file path to the image.\n",
    "\n",
    "    Returns:\n",
    "        - str: The extracted text from the image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image file\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Extract text from the image using Tesseract OCR\n",
    "        text = pytesseract.image_to_string(img)\n",
    "\n",
    "        # Remove newline characters for better formatting\n",
    "        text = text.replace('\\n', '')\n",
    "\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle exceptions and return an empty string on failure\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27df449",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_and_convert_img2txt(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95e7acbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6: IBM, SAP, Pure Storage, Nordstorm, Groupon,Norton Lifelock, Yahoo, PNC, NetApp, GoDaddy,'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae07e8fd",
   "metadata": {},
   "source": [
    "If you take a look, you'll see that the text we get is all in one string. To make things easier to handle, we tidy up the data. We use basic string operations to break that single string into a list, organizing the information neatly. After that, we use list comprehension to go through the list and arrange the information in a more organized way. This helps us manage the data in a more structured manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36a868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79e7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list = text.split(':')[1:]\n",
    "companies_list = [s.rstrip(string.digits) for s in companies_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ffeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list = [s.split(',') for s in companies_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94b0192d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' IBM',\n",
       "  ' SAP',\n",
       "  ' Pure Storage',\n",
       "  ' Nordstorm',\n",
       "  ' Groupon',\n",
       "  'Norton Lifelock',\n",
       "  ' Yahoo',\n",
       "  ' PNC',\n",
       "  ' NetApp',\n",
       "  ' GoDaddy',\n",
       "  '']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070faea",
   "metadata": {},
   "source": [
    "Rather than making things complicated by dealing with a list inside another list or using multiple loops, I opted for a simpler solution. So, we're using a tool called 'itertools' to change our two-dimensional list into a simpler one-dimensional form. This makes our data handling easier and the code more straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fef4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2970e4c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "companies_tier = list(itertools.chain(*companies_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3b324e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' IBM',\n",
       " ' SAP',\n",
       " ' Pure Storage',\n",
       " ' Nordstorm',\n",
       " ' Groupon',\n",
       " 'Norton Lifelock',\n",
       " ' Yahoo',\n",
       " ' PNC',\n",
       " ' NetApp',\n",
       " ' GoDaddy',\n",
       " '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacfc02d",
   "metadata": {},
   "source": [
    "Now, we will save our data in a user-friendly format - CSV. For this purpose, we are employing the csv library and its csv.writer class to efficiently write the data into our CSV file. It's worth noting that, in this simplified project, we are not checking if the file already exists or overwriting the data. In more complex scenarios, it's considered best practice to handle such cases for reusability and to prevent potential data loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c676619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c23dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SampleJobLinks.csv', 'w') as file:\n",
    "     \n",
    "    # using csv.writer method from CSV package\n",
    "    writer = csv.writer(file)\n",
    "    for val in companies_tier:\n",
    "        writer.writerow([val])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092acc60",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b468a0b5",
   "metadata": {},
   "source": [
    "Now, here comes the intriguing part – we're reading this list, searching for career pages associated with each company, and then saving it in CSV file. This time, we're not only storing the company names but also including their corresponding URLs. This step enhances our dataset by providing valuable links to the career pages of each identified company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609dc9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from googlesearch import search\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fb165ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('SampleJobLinks.csv', encoding='cp1252', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6d8c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_url(company_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Searches for the URL of a company's career page using two keywords: the company name and the string \"Careers\".\n",
    "\n",
    "    Parameters:\n",
    "        - company_name (str): The name of the company for which the career page URL is to be searched.\n",
    "\n",
    "    Returns:\n",
    "        - str: The URL of the company's career page, or an empty string if the search is unsuccessful.\n",
    "\n",
    "    Raises:\n",
    "        - Exception: Raises an exception if there is an issue with the search process.\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Combining company name and 'Careers' as search terms\n",
    "        search_terms = ' '.join([company_name, 'Careers'])\n",
    "        \n",
    "        # Performing a Google search to find the career page URL\n",
    "        for url in search(search_terms, num_results=1):\n",
    "            return url\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "038f86a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pure Storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nordstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Groupon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Norton Lifelock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NetApp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GoDaddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "0               IBM\n",
       "1               SAP\n",
       "2      Pure Storage\n",
       "3         Nordstorm\n",
       "4           Groupon\n",
       "5   Norton Lifelock\n",
       "6             Yahoo\n",
       "7               PNC\n",
       "8            NetApp\n",
       "9           GoDaddy\n",
       "10              NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78fb83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f56e626d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pure Storage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nordstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Groupon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Norton Lifelock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yahoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PNC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NetApp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GoDaddy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "0              IBM\n",
       "1              SAP\n",
       "2     Pure Storage\n",
       "3        Nordstorm\n",
       "4          Groupon\n",
       "5  Norton Lifelock\n",
       "6            Yahoo\n",
       "7              PNC\n",
       "8           NetApp\n",
       "9          GoDaddy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c57ed906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_25388\\3967327771.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['URL'] = ''\n"
     ]
    }
   ],
   "source": [
    "df['URL'] = ''\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index, 'URL'] = getURL(str(row[0]))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6721ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = df.shape[0] +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "884b6e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://www.linkedin.com/jobs/ibm-jobs-boston-ma\n",
       "1                               https://jobs.sap.com/\n",
       "2    https://www.purestorage.com/company/careers.html\n",
       "3                      https://careers.nordstrom.com/\n",
       "4          https://groupon.wd5.myworkdayjobs.com/jobs\n",
       "5       https://www.nortonlifelock.com/us/en/careers/\n",
       "6                   https://www.yahooinc.com/careers/\n",
       "7                   https://careers.pnc.com/global/en\n",
       "8                         https://careers.netapp.com/\n",
       "9                            https://careers.godaddy/\n",
       "Name: URL, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e025e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IBM</td>\n",
       "      <td>https://www.linkedin.com/jobs/ibm-jobs-boston-ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAP</td>\n",
       "      <td>https://jobs.sap.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pure Storage</td>\n",
       "      <td>https://www.purestorage.com/company/careers.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nordstorm</td>\n",
       "      <td>https://careers.nordstrom.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Groupon</td>\n",
       "      <td>https://groupon.wd5.myworkdayjobs.com/jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Norton Lifelock</td>\n",
       "      <td>https://www.nortonlifelock.com/us/en/careers/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://www.yahooinc.com/careers/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PNC</td>\n",
       "      <td>https://careers.pnc.com/global/en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NetApp</td>\n",
       "      <td>https://careers.netapp.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GoDaddy</td>\n",
       "      <td>https://careers.godaddy/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                                               URL\n",
       "0              IBM  https://www.linkedin.com/jobs/ibm-jobs-boston-ma\n",
       "1              SAP                             https://jobs.sap.com/\n",
       "2     Pure Storage  https://www.purestorage.com/company/careers.html\n",
       "3        Nordstorm                    https://careers.nordstrom.com/\n",
       "4          Groupon        https://groupon.wd5.myworkdayjobs.com/jobs\n",
       "5  Norton Lifelock     https://www.nortonlifelock.com/us/en/careers/\n",
       "6            Yahoo                 https://www.yahooinc.com/careers/\n",
       "7              PNC                 https://careers.pnc.com/global/en\n",
       "8           NetApp                       https://careers.netapp.com/\n",
       "9          GoDaddy                          https://careers.godaddy/"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e333ed91",
   "metadata": {},
   "source": [
    "</br></br>\n",
    "**Note** - *Deciding whether to update the current file or make a new one has its own pros and cons. Updating the same file saves space and keeps things organized but might risk losing data if something goes wrong. Creating a new file keeps your original data safe, acts as a backup, and helps track different versions, but it takes up more space and can be confusing with lots of versions. The best choice depends on your project and how important your data is. (I prefer latter than former)*\n",
    "\n",
    "I am creating a new file with timestamp to keep track of different versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25e27cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48cd1734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframe_to_csv_with_timestamp(dataframe, base_filename='samplejoblinks'):\n",
    "    \"\"\"\n",
    "    Writes a DataFrame to a CSV file with a timestamp.\n",
    "\n",
    "    Parameters:\n",
    "        - dataframe: The DataFrame to be written to CSV.\n",
    "        - base_filename: The base name for the CSV file (default is 'data').\n",
    "\n",
    "    Returns:\n",
    "        - csv_file_name: The name of the generated CSV file.\n",
    "    \"\"\"\n",
    "    # Generate a timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    csv_file_name = f'{base_filename}_{timestamp}.csv'\n",
    "\n",
    "    dataframe.to_csv(csv_file_name, index=False)\n",
    "\n",
    "    return csv_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6919e621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been successfully written to samplejoblinks_20240228_191329.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_name = write_dataframe_to_csv_with_timestamp(df)\n",
    "print(f'DataFrame has been successfully written to {csv_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91813d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imageTotext)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
